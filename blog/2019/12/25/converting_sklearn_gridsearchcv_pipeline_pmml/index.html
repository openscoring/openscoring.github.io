<!DOCTYPE html>
<html lang="en">

<head>
  <script src="https://www.googletagmanager.com/gtag/js?id=G-1XC1KCZX17" async></script>

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'G-1XC1KCZX17');
</script>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0">
  <meta name="format-detection" content="telephone=no">
  <meta name="theme-color" content="#ffffff">
  <meta name="msapplication-navbutton-color" content="#ffffff">
  <meta name="apple-mobile-web-app-status-bar-style" content="#ffffff">

  <meta name="description" content="">
  <meta name="keywords" content="scikit-learn sklearn2pmml tuning">
  <meta name="author" content="vruusmann">

  <title>Converting Scikit-Learn GridSearchCV pipelines to PMML - Openscoring</title>

  <meta name="robots" content="index, follow, max-snippet:-1, max-video-preview:-1, max-image-preview:large">
  <link rel="canonical" href="https://openscoring.io/blog/2019/12/25/converting_sklearn_gridsearchcv_pipeline_pmml/">
  <meta property="og:locale" content="en_US">
  <meta property="og:type" content="website">
  <meta property="og:title" content="Converting Scikit-Learn GridSearchCV pipelines to PMML - Openscoring">
  <meta property="og:url" content="/blog/2019/12/25/converting_sklearn_gridsearchcv_pipeline_pmml/">
  <meta property="og:site_name" content="Openscoring">
  <meta property="og:updated_time" content="2019-12-25 00:00:00 +0200">
  <meta property="article:published_time" content="2019-12-25 00:00:00 +0200">
  <meta property="article:modified_time" content="2019-12-25 00:00:00 +0200">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Converting Scikit-Learn GridSearchCV pipelines to PMML - Openscoring">
  <meta name="twitter:label1" content="Written by">
  <meta name="twitter:data1" content="Villu Ruusmann">
  <meta name="twitter:label2" content="Time to read">
  <meta name="twitter:data2" content="Less than a minute">

  <link rel="icon" href="/assets/images/fa-150x150.png" sizes="32x32">
  <link rel="icon" href="/assets/images/fa.png" sizes="192x192">
  <link rel="apple-touch-icon" href="/assets/images/fa.png">
  <link rel="stylesheet" href="/assets/css/main.css">
  <meta name="msapplication-TileImage" content="h/assets/images/fa.png">
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->
</head>

<body>
  <header class="header">
  <div class="container">
    <nav class="nav--main">
      <a class="logo" href="/" aria-label="home">
        <img src="/assets/images/logo.svg" alt="" width="35" height="32" loading="lazy">
        <span>Openscoring</span>
      </a>

      <input type="checkbox" id="nav__toggle--main" class="nav__toggle">
      <label for="nav__toggle--main">Menu<span></span></label>

      <div class="menu">
        <ul id="menu--main">
          <li><a href="/#overview" aria-current="page">Overview</a></li>
          <li><a href="/#products" aria-current="page">Products</a></li>
          <li><a href="/#licensing" aria-current="page">Licensing</a></li>
          <li><a href="/#consulting" aria-current="page">Consulting</a></li>
        </ul>
      </div>

      <label for="nav__toggle--main" class="overlay"></label>

      <a href="/blog/" class="btn btn--small">Blog</a>
    </nav>
  </div>
</header>

  <main class="container mt-26">
    <h1>Converting Scikit-Learn GridSearchCV pipelines to PMML</h1>
  
<div class="post">
  <p>The behaviour of Scikit-Learn estimators is controlled using hyperparameters.
Feature transformers and selectors perform deterministic computations that take a very limited number of very transparent hyperparameters.
In contrast, models perform non-deterministic computations (numerical optimization) that take a much larger number of rather obscure hyperparameters.
Some of them control the complexity of the learned model object, whereas some others control the quality and speed of the learning process itself.</p>

<p>Scikit-Learn estimators assign reasonable default values to hyperparameters in their constructors.
This facilitates prototyping work, where the goal is to establish the structure of a pipeline by quickly adding or modifying steps.
However, the default configuration is hardly ever the optimal one.</p>

<p>There is no analytic procedure for determining the best configuration from scratch, or even comparing two configurations goodness-wise.
In practice, the most common way of finding a good configuration is to generate many configurations, and rank them on the basis of their predictive performance on a testing dataset.</p>

<p>The <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection">Model Selection</a> module provides meta-estimators and utility functions for developing robust solutions in this area.</p>

<p>In brief, a data scientist defines the template pipeline and the associated hyperparameter space.
The latter is a mapping between parameter names and parameter value ranges (a list of preselected values, or a distribution function).
If the dimensionality of the hyperparameter space is low, and the gradation of all individual dimensions is directly enumerable, then it is possible to perform exhaustive search using the <code class="language-plaintext highlighter-rouge">GridSearchCV</code> meta-estimator.
In all other cases, it is possible to perform random sampling using the <code class="language-plaintext highlighter-rouge">RandomizedSearchCV</code> meta-estimator.</p>

<h2 id="single-estimator-aka-local-tuning">Single estimator (aka local) tuning</h2>

<p>If the pipeline contains just one tuneable estimator, then the tuning work should be performed locally, by wrapping this estimator in its current place into a search meta-estimator:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn_pandas</span> <span class="kn">import</span> <span class="n">DataFrameMapper</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelBinarizer</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn2pmml</span> <span class="kn">import</span> <span class="n">sklearn2pmml</span>
<span class="kn">from</span> <span class="nn">sklearn2pmml.decoration</span> <span class="kn">import</span> <span class="n">CategoricalDomain</span><span class="p">,</span> <span class="n">ContinuousDomain</span>
<span class="kn">from</span> <span class="nn">sklearn2pmml.pipeline</span> <span class="kn">import</span> <span class="n">PMMLPipeline</span>

<span class="n">mapper</span> <span class="o">=</span> <span class="n">DataFrameMapper</span><span class="p">(</span>
  <span class="p">[(</span><span class="n">cat_column</span><span class="p">,</span> <span class="p">[</span><span class="n">CategoricalDomain</span><span class="p">(),</span> <span class="n">LabelBinarizer</span><span class="p">()])</span> <span class="k">for</span> <span class="n">cat_column</span> <span class="ow">in</span> <span class="n">cat_columns</span><span class="p">]</span> <span class="o">+</span>
  <span class="p">[([</span><span class="n">cont_column</span><span class="p">],</span> <span class="p">[</span><span class="n">ContinuousDomain</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">()])</span> <span class="k">for</span> <span class="n">cont_column</span> <span class="ow">in</span> <span class="n">cont_columns</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">multi_class</span> <span class="o">=</span> <span class="s">"ovr"</span><span class="p">,</span> <span class="n">penalty</span> <span class="o">=</span> <span class="s">"elasticnet"</span><span class="p">,</span> <span class="n">solver</span> <span class="o">=</span> <span class="s">"saga"</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">"l1_ratio"</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">PMMLPipeline</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"mapper"</span><span class="p">,</span> <span class="n">mapper</span><span class="p">),</span>
  <span class="p">(</span><span class="s">"classifier"</span><span class="p">,</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span><span class="p">))</span>
<span class="p">])</span>
<span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_X</span><span class="p">,</span> <span class="n">df_y</span><span class="p">)</span>
<span class="n">pipeline</span><span class="p">.</span><span class="n">verify</span><span class="p">(</span><span class="n">df_X</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">sklearn2pmml</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="s">"GridSearchAudit.pmml"</span><span class="p">)</span>
</code></pre></div></div>

<p>Both <code class="language-plaintext highlighter-rouge">GridSearchCV</code> and <code class="language-plaintext highlighter-rouge">RandomizedSearchCV</code> meta-estimators split the original dataset into training and validation subsets.
As a result, the fit method of the tuneable estimator is exposed to less data records than the fit methods of all the other estimators in the pipeline.
For example, in the above Python code, the <code class="language-plaintext highlighter-rouge">LogisticRegression.fit(X, y)</code> method is called with roughly 80% of data records (the training subset of the original dataset), whereas <code class="language-plaintext highlighter-rouge">LabelBinarizer.fit(X)</code> and <code class="language-plaintext highlighter-rouge">StandardScaler.fit(X)</code> methods are called with 100% of data records (full original dataset).
Data scientists may want to compensate for this effect, especially when working with smaller and more heterogeneous datasets.</p>

<h2 id="pipeline-aka-global-tuning">Pipeline (aka global) tuning</h2>

<p>If the pipeline contains multiple tuneable estimators, then the tuning work should be performed globally, by wrapping the complete pipeline into a search meta-estimator:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span>

<span class="n">mapper</span> <span class="o">=</span> <span class="n">DataFrameMapper</span><span class="p">(</span>
  <span class="p">[(</span><span class="n">cat_column</span><span class="p">,</span> <span class="p">[</span><span class="n">CategoricalDomain</span><span class="p">(</span><span class="n">invalid_value_treatment</span> <span class="o">=</span> <span class="s">"as_is"</span><span class="p">),</span> <span class="n">LabelBinarizer</span><span class="p">()])</span> <span class="k">for</span> <span class="n">cat_column</span> <span class="ow">in</span> <span class="n">cat_columns</span><span class="p">]</span> <span class="o">+</span>
  <span class="p">[([</span><span class="n">cont_column</span><span class="p">],</span> <span class="p">[</span><span class="n">ContinuousDomain</span><span class="p">(</span><span class="n">invalid_value_treatment</span> <span class="o">=</span> <span class="s">"as_is"</span><span class="p">),</span> <span class="n">StandardScaler</span><span class="p">()])</span> <span class="k">for</span> <span class="n">cont_column</span> <span class="ow">in</span> <span class="n">cont_columns</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">()</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">multi_class</span> <span class="o">=</span> <span class="s">"ovr"</span><span class="p">,</span> <span class="n">penalty</span> <span class="o">=</span> <span class="s">"elasticnet"</span><span class="p">,</span> <span class="n">solver</span> <span class="o">=</span> <span class="s">"saga"</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">PMMLPipeline</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"mapper"</span><span class="p">,</span> <span class="n">mapper</span><span class="p">),</span>
  <span class="p">(</span><span class="s">"selector"</span><span class="p">,</span> <span class="n">selector</span><span class="p">),</span>
  <span class="p">(</span><span class="s">"classifier"</span><span class="p">,</span> <span class="n">classifier</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">"selector__k"</span> <span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
  <span class="s">"classifier__l1_ratio"</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">searcher</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span><span class="p">)</span>
<span class="n">searcher</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_X</span><span class="p">,</span> <span class="n">df_y</span><span class="p">)</span>

<span class="n">best_pipeline</span> <span class="o">=</span> <span class="n">searcher</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">best_pipeline</span><span class="p">.</span><span class="n">verify</span><span class="p">(</span><span class="n">df_X</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">sklearn2pmml</span><span class="p">(</span><span class="n">best_pipeline</span><span class="p">,</span> <span class="s">"GridSearchAudit.pmml"</span><span class="p">)</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">GridSearchCV</code> meta-estimator can be regarded as a workflow execution engine.
It takes a template pipeline, performs the search, and returns a hyperparameter-tuned clone of this template pipeline as a <code class="language-plaintext highlighter-rouge">best_estimator_</code> attribute.</p>

<p>All hyperparameter spaces are collected into a single map.
They are kept separate from one another logically by prefixing parameter names with the step identifier.</p>

<p>The search meta-estimator is still splitting the original dataset into two subsets.
However, the split happens before the workflow execution enters the <code class="language-plaintext highlighter-rouge">(PMML)Pipeline.fit(X, y)</code> method, so all estimators in the pipeline are exposed to the same number of data records.</p>

<p>If the span of a validation subset exceeds that of a training subset, then the corresponding cross-validation fold shall fail with a value error:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Traceback (most recent call last):
  File "train-global.py", line 41, in &lt;module&gt;
    searcher.fit(df_X, df_y)
  File "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py", line 712, in fit
    self._run_search(evaluate_candidates)
  File "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py", line 1153, in _run_search
    evaluate_candidates(ParameterGrid(self.param_grid))
  File "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py", line 691, in evaluate_candidates
    cv.split(X, y, groups)))
  ...
  File "/usr/local/lib/python3.7/site-packages/sklearn/pipeline.py", line 613, in score
    Xt = transform.transform(Xt)
  File "/usr/local/lib/python3.7/site-packages/sklearn_pandas/dataframe_mapper.py", line 377, in transform
    return self._transform(X)
  File "/usr/local/lib/python3.7/site-packages/sklearn_pandas/dataframe_mapper.py", line 306, in _transform
    Xt = transformers.transform(Xt)
  File "/usr/local/lib/python3.7/site-packages/sklearn/pipeline.py", line 555, in _transform
    Xt = transform.transform(Xt)
  File "/usr/local/lib/python3.7/site-packages/sklearn2pmml/decoration/__init__.py", line 119, in transform
    self._transform_invalid_values(X, invalid_value_mask)
  File "/usr/local/lib/python3.7/site-packages/sklearn2pmml/decoration/__init__.py", line 103, in _transform_invalid_values
    raise ValueError("Data contains {0} invalid values".format(numpy.count_nonzero(where)))
ValueError: Employment: Data contains 1 invalid values
</code></pre></div></div>

<p>It is possible to suppress this sanity check by changing the value of the <code class="language-plaintext highlighter-rouge">Domain.invalid_value_treatment</code> attribute from <code class="language-plaintext highlighter-rouge">return_invalid</code> to <code class="language-plaintext highlighter-rouge">as_is</code>.</p>

<h2 id="resources">Resources</h2>

<ul>
  <li>Dataset: <a href="https://openscoring.io/resources/data/audit.csv"><code class="language-plaintext highlighter-rouge">audit.csv</code></a></li>
  <li>Python scripts: <a href="https://openscoring.io/resources/2019-12-25/train-local.py"><code class="language-plaintext highlighter-rouge">train-local.py</code></a> and <a href="https://openscoring.io/resources/2019-12-25/train-global.py"><code class="language-plaintext highlighter-rouge">train-global.py</code></a></li>
</ul>


  <h2 id="related_posts">Related blog posts</h2>

  <ul class="posts">
  
    
    
      <li class="post__item">
        <div class="post__date">2023-10-15</div>
        <a class="post__title" href="/blog/2023/10/15/sklearn_statsmodels_gridsearchcv_pipeline/">Training Scikit-Learn GridSearchCV StatsModels pipelines</a>
        <div class="post__description"></div>
      </li>
    
  
  </ul>

<h2>Feedback</h2>

<script src="https://giscus.app/client.js"
  data-repo="vruusmann/openscoring.io"
  data-repo-id="R_kgDOH23Yfg"
  data-category="Blog"
  data-category-id="DIC_kwDOH23Yfs4CaTiG"
  data-mapping="url"
  data-strict="0"
  data-reactions-enabled="0"
  data-emit-metadata="0"
  data-input-position="bottom"
  data-theme="light"
  data-lang="en"
  data-loading="lazy"
  crossorigin="anonymous"
  async>
</script>

</div>

  </main>

  <footer class="footer">
  <div class="container">
    <div class="mb-6">© 2022 - Openscoring</div>

    <div class="mb-6">
      <ul class="flex gap-4 list-none">
        <li>
          <a href="mailto:info@openscoring.io" aria-label="email">
            <img src="/assets/images/email_round.svg" width="48" height="48" alt="Contact Openscoring">
          </a>
        </li>
        <li>
          <a href="https://twitter.com/openscoring" target="_blank" aria-label="twitter">
            <img src="/assets/images/twitter_round.svg" width="48" height="48" alt="Follow Openscoring on Twitter">
          </a>
        </li>
      </ul>
    </div>
  </div>
</footer>

  <script>
  var sc_project=11704106;
  var sc_security="a7d1bf16"; 
  var sc_invisible=1; 
  var sc_remove_link=1; 
</script>

<script src="https://www.statcounter.com/counter/counter.js" async></script>

<noscript>
  <div class="statcounter">
    <img class="statcounter" src="https://c.statcounter.com/11704106/0/a7d1bf16/1/" alt="Web Analytics Made Easy - Statcounter" referrerPolicy="no-referrer-when-downgrade">
  </div>
</noscript>
</body>

</html>
