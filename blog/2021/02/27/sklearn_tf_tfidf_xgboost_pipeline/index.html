<!DOCTYPE html>
<html lang=" en-US">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0" />
  <meta name="format-detection" content="telephone=no">
  <meta name="theme-color" content="#ffffff" />
  <meta name="msapplication-navbutton-color" content="#ffffff">
  <meta name="apple-mobile-web-app-status-bar-style" content="#ffffff">

  <meta name="description" content="">
  <meta name="keywords" content="scikit-learn xgboost mlxtend sklearn2pmml tf-idf data-missing">
  <meta name="author" content="vruusmann">

  <title>Training Scikit-Learn based TF(-IDF) plus XGBoost pipelines - Openscoring</title>

  <meta name="robots" content="index, follow, max-snippet:-1, max-video-preview:-1, max-image-preview:large" />
  <link rel="canonical" href="https://openscoring.io/blog/2021/02/27/sklearn_tf_tfidf_xgboost_pipeline/" />
  <meta property="og:locale" content="en_US" />
  <meta property="og:type" content="website" />
  <meta property="og:title" content="Training Scikit-Learn based TF(-IDF) plus XGBoost pipelines - Openscoring" />
  <meta property="og:url" content="/blog/2021/02/27/sklearn_tf_tfidf_xgboost_pipeline/" />
  <meta property="og:site_name" content="Openscoring" />
  <meta property="og:updated_time" content="2021-02-27 00:00:00 +0200" />
  <meta property="article:published_time" content="2021-02-27 00:00:00 +0200" />
  <meta property="article:modified_time" content="2021-02-27 00:00:00 +0200" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Training Scikit-Learn based TF(-IDF) plus XGBoost pipelines - Openscoring" />
  <meta name="twitter:label1" content="Written by" />
  <meta name="twitter:data1" content="Villu Ruusmann" />
  <meta name="twitter:label2" content="Time to read" />
  <meta name="twitter:data2" content="Less than a minute" />

  <link rel="icon" href="/assets/images/fa-150x150.png" sizes="32x32" />
  <link rel="icon" href="/assets/images/fa.png" sizes="192x192" />
  <link rel="apple-touch-icon" href="/assets/images/fa.png" />
  <link rel="stylesheet" href="/assets/css/main.css">
  <meta name="msapplication-TileImage" content="h/assets/images/fa.png" />
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->
</head>

<body>
  <header class="header">
  <div class="container">
    <nav class="nav--main">
      <a class="logo" href="/" aria-label="home">
        <img src="/assets/images/logo.svg" alt="" width="35" height="32" loading="lazy">
        <span>Openscoring.IO</span>
      </a>

      <input type="checkbox" id="nav__toggle--main" class="nav__toggle">
      <label for="nav__toggle--main">Menu<span></span></label>

      <div class="menu">
        <ul id="menu--main">
          <li><a href="/#overview" aria-current="page">Overview</a></li>
          <li><a href="/#products" aria-current="page">Products</a></li>
          <li><a href="/#licensing" aria-current="page">Licensing</a></li>
          <li><a href="/#consulting" aria-current="page">Consulting</a></li>
        </ul>
      </div>

      <label for="nav__toggle--main" class="overlay"></label>

      <a href="/blog/" class="btn btn--small">Blog</a>
    </nav>
  </div>
</header>

  <main class="container mt-26">
    <h1>Training Scikit-Learn based TF(-IDF) plus XGBoost pipelines</h1>
  
<div class="post">
  <h3 id="you-have-been-doing-it-wrong">You have been doing it wrong</h3>

<p>Consider the simplest TF(-IDF) plus XGBoost pipeline:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"countvectorizer"</span><span class="p">,</span> <span class="n">CountVectorizer</span><span class="p">()),</span>
  <span class="p">(</span><span class="s">"classifier"</span><span class="p">,</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">13</span><span class="p">))</span>
<span class="p">])</span>
</code></pre></div></div>

<p><strong>Is this pipeline correct or not</strong>?</p>

<p>The question is not about spotting a typo, or optimizing the default parameterization.
The question is “are you allowed to pass the document-term matrix of <code class="language-plaintext highlighter-rouge">CountVectorizer</code> (or any of its subclasses such as <code class="language-plaintext highlighter-rouge">TfidfVectorizer</code>) directly to <code class="language-plaintext highlighter-rouge">XGBClassifier</code>, or not?”.</p>

<p>This pipeline can be fitted without any errors or warnings, and appears to make sensible predictions.
Therefore, the anwser must be “yes”, right?</p>

<p>Not so fast! The executability proves technical compatibility, but it does not prove logical compatibility.</p>

<p>Despite adhering to the standard Scikit-Learn API, these two pipeline steps both exhibit slightly non-standard behaviour. 
First, the <code class="language-plaintext highlighter-rouge">transform(X)</code> method of Scikit-Learn TF(-IDF) transformers produces sparse not dense data matrices.
For example, the “sentiment” dataset is expanded into a compressed sparse row (CSR) <code class="language-plaintext highlighter-rouge">scipy.sparse.csr.csr_matrix</code> data matrix of shape <code class="language-plaintext highlighter-rouge">(1000, 1847)</code>, which has ~0.005 density (ie. only 0.5% of cells hold non-zero values).
Second, the <code class="language-plaintext highlighter-rouge">fit(X, y)</code> and <code class="language-plaintext highlighter-rouge">predict(X)</code> methods of XGBoost estimators accept most common <a href="https://scipy.org/">SciPy</a>, <a href="https://numpy.org/">NumPy</a> and <a href="https://pandas.pydata.org/">Pandas</a> data structures.
However, behind the scenes, they are all converted to a proprietary <code class="language-plaintext highlighter-rouge">xgboost.DMatrix</code> data matrix.</p>

<p>It is possible to reduce complexity in the contact area by explicitly converting the document-term matrix from sparse to dense representation.</p>

<p>The <code class="language-plaintext highlighter-rouge">CountVectorizer</code> transformer does not provide any controls (eg. a “sparse” constructor parameter) for that.
A good workaround is to use the <code class="language-plaintext highlighter-rouge">mlxtend.preprocessing.DenseTransformer</code> pseudo-transformer from the <a href="https://github.com/rasbt/mlxtend"><code class="language-plaintext highlighter-rouge">mlxtend</code></a> package:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">mlxtend.preprocessing</span> <span class="kn">import</span> <span class="n">DenseTransformer</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"countvectorizer"</span><span class="p">,</span> <span class="n">CountVectorizer</span><span class="p">()),</span>
  <span class="p">(</span><span class="s">"densifier"</span><span class="p">,</span> <span class="n">DenseTransformer</span><span class="p">()),</span>
  <span class="p">(</span><span class="s">"classifier"</span><span class="p">,</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">13</span><span class="p">))</span>
<span class="p">])</span>
</code></pre></div></div>

<p>This pipeline (dense) should be functionally identical to the first one (sparse), but somehow it is making different predictions!
For example, the predicted probabilities for the first data record of the “sentiment” dataset are <code class="language-plaintext highlighter-rouge">[0.9592051, 0.04079489]</code> and <code class="language-plaintext highlighter-rouge">[0.976111, 0.02388901]</code>, respectively.</p>

<p>Clearly, one of the two pipelines must be incorrect.</p>

<h3 id="untangling-the-mess">Untangling the mess</h3>

<p>The situation cannot be definitively cleared up by making more predictions, or exploring the documentation and Python source code of relevant classes and methods.</p>

<p>Converting the pipeline to Predictive Model Markup Language (PMML) data format, and making predictions using a PMML engine provides an objective (ie. first-principles) second opinion.</p>

<p>Converting using the <a href="https://github.com/jpmml/sklearn2pmml"><code class="language-plaintext highlighter-rouge">sklearn2pmml</code></a> package:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn2pmml</span> <span class="kn">import</span> <span class="n">make_pmml_pipeline</span><span class="p">,</span> <span class="n">sklearn2pmml</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(...)</span>

<span class="n">pmml_pipeline</span> <span class="o">=</span> <span class="n">make_pmml_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">active_fields</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Sentence"</span><span class="p">],</span> <span class="n">target_fields</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Score"</span><span class="p">])</span>

<span class="n">sklearn2pmml</span><span class="p">(</span><span class="n">pmml_pipeline</span><span class="p">,</span> <span class="s">"XGBSentiment.pmml"</span><span class="p">)</span>
</code></pre></div></div>

<p>In the current case, it does not matter which pipeline of the two is converted.
The resulting PMML documents will be identical (except for the conversion timestamp in the header), because the <code class="language-plaintext highlighter-rouge">DenseTransformer</code> pseudo-transformation is no-op.</p>

<p>Making predictions using the <a href="https://github.com/jpmml/jpmml-evaluator-python"><code class="language-plaintext highlighter-rouge">jpmml_evaluator</code></a> package:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">jpmml_evaluator</span> <span class="kn">import</span> <span class="n">make_evaluator</span>
<span class="kn">from</span> <span class="nn">jpmml_evaluator.pyjnius</span> <span class="kn">import</span> <span class="n">jnius_configure_classpath</span><span class="p">,</span> <span class="n">PyJNIusBackend</span>

<span class="kn">import</span> <span class="nn">pandas</span>

<span class="n">jnius_configure_classpath</span><span class="p">()</span>

<span class="n">evaluator</span> <span class="o">=</span> <span class="n">make_evaluator</span><span class="p">(</span><span class="n">PyJNIusBackend</span><span class="p">(),</span> <span class="s">"XGBSentiment.pmml"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">verify</span><span class="p">()</span>

<span class="n">arguments</span> <span class="o">=</span> <span class="n">pandas</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"sentiment.csv"</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">evaluator</span><span class="p">.</span><span class="n">evaluateAll</span><span class="p">(</span><span class="n">arguments</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
</code></pre></div></div>

<p>PMML predictions are in perfect agreement with the predictions of the second pipeline (dense).</p>

<p><strong>It follows that the first pipeline (sparse) is indeed incorrect</strong>.</p>

<p>The source of the error is the algorithm that the XGBoost library uses for converting <code class="language-plaintext highlighter-rouge">scipy.sparse.csr.csr_matrix</code> to <code class="language-plaintext highlighter-rouge">xgboost.DMatrix</code>.</p>

<p>The document-term matrix keeps count how many times each document (rows) contains each term (columns).
The cell value is set only if the count is greater than zero.
The DMatrix converter appears to interpret unset cell values as missing values (<code class="language-plaintext highlighter-rouge">NaN</code>) rather than zero count values (<code class="language-plaintext highlighter-rouge">0</code>).
In plain english, these interpretations read like “I do not know if the document contains the specified term” and “I know that the document contains zero occurrences of the specified term”, respectively.</p>

<p>Scikit-Learn estimators typically error out when they encounter <code class="language-plaintext highlighter-rouge">NaN</code> values.
In contrast, XGBoost estimators treat <code class="language-plaintext highlighter-rouge">NaN</code> values as special-purpose missing value indicator values, and grow missing value-aware decision trees.</p>

<p>When comparing XGBoost estimators between the first and the second pipeline, then they are structurally different (overall vocabulary, the time and location of invoking individual terms, etc).
The former incorrectly believes that it was dealing with massive amounts of missing values during training, and all its internals are thus systematically off.</p>

<p>A data scientist may evaluate such a biased TF(-IDF) plus XGBoost pipeline with a validation dataset, and decide that its raw numeric performance is still good enough for productionization.
It would be okay. The Pipeline API provides adequate guarantees that all biases survive and are consistently applied throughout the pipeline life-cycle.</p>

<h3 id="doing-it-right">Doing it right</h3>

<p>As of XGBoost 1.3(.3), the <code class="language-plaintext highlighter-rouge">missing</code> constructor parameter has no effect:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"countvectorizer"</span><span class="p">,</span> <span class="n">CountVectorizer</span><span class="p">()),</span>
  <span class="c1"># Map missing value indicator value to -1 in the hope that this will change the interpretation of unset cell values from missing values to zero count values
</span>  <span class="p">(</span><span class="s">"classifier"</span><span class="p">,</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">mising</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">13</span><span class="p">))</span>
<span class="p">])</span>
<span class="c1"># Raises a UserWarning: "`missing` is not used for current input data type:&lt;class 'scipy.sparse.csr.csr_matrix'&gt; str(type(data)))"
</span><span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"Sentence"</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">"Score"</span><span class="p">])</span>
</code></pre></div></div>

<p>This user warning should be taken seriously, and the fitted pipeline abandoned, because it is incorrect again.</p>

<p>Converting the document-term matrix from sparse to dense representation is good for quick troubleshooting purposes.
However, it is prohibitively expensive in real-life situations where the dimensions of data matrices easily reach millions of rows (documents) and/or tens of thousands of columns (terms).</p>

<p>The solution is to perform the conversion from <code class="language-plaintext highlighter-rouge">scipy.sparse.csr.csr_matrix</code> to <code class="language-plaintext highlighter-rouge">xgboost.DMatrix</code> over a temporary sparse <code class="language-plaintext highlighter-rouge">pandas.DataFrame</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"Sentence"</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"Score"</span><span class="p">]</span>

<span class="n">countvectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">Xt</span> <span class="o">=</span> <span class="n">countvectorizer</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Convert from csr_matrix to sparse DataFrame
</span><span class="n">Xt_df_sparse</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="p">.</span><span class="n">sparse</span><span class="p">.</span><span class="n">from_spmatrix</span><span class="p">(</span><span class="n">Xt</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"DF density: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">Xt_df_sparse</span><span class="p">.</span><span class="n">sparse</span><span class="p">.</span><span class="n">density</span><span class="p">))</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">13</span><span class="p">)</span>
<span class="n">classifier</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xt_df_sparse</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">yt_proba</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">Xt_df_sparse</span><span class="p">)</span>
</code></pre></div></div>

<p>The above TF(-IDF) plus XGBoost sequence is correct in a sense that unset cell values are interpreted as zero count values.</p>

<p>The only problem is that this sequence cannot be “formatted” as a <code class="language-plaintext highlighter-rouge">Pipeline</code> object, because there is no reusable (pseudo-)transformer that would implement the intermediate <code class="language-plaintext highlighter-rouge">DataFrame.sparse.from_spmatrix(data)</code> method invocation.</p>

<p>However, fitted pipeline steps can be combined into a temporary pipeline for PMML conversion purposes:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">countvectorizer</span><span class="p">,</span> <span class="n">classifier</span><span class="p">)</span>

<span class="n">pmml_pipeline</span> <span class="o">=</span> <span class="n">make_pmml_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">active_fields</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Sentence"</span><span class="p">],</span> <span class="n">target_fields</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Score"</span><span class="p">])</span>

<span class="n">sklearn2pmml</span><span class="p">(</span><span class="n">pmml_pipeline</span><span class="p">,</span> <span class="s">"XGBSentiment.pmml"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="resources">Resources</h3>

<ul>
  <li>“Sentiment” dataset: <a href="https://openscoring.io/resources/data/sentiment.csv"><code class="language-plaintext highlighter-rouge">sentiment.csv</code></a></li>
  <li>Python script: <a href="https://openscoring.io/resources/2021-02-27/train.py"><code class="language-plaintext highlighter-rouge">train.py</code></a></li>
</ul>

</div>



  </main>

  <footer class="footer">
  <div class="container">
    <div class="mb-6">© 2022 - Openscoring.IO</div>

    <div class="mb-6">
      <ul class="flex gap-4 list-none">
        <li>
          <a href="mailto:info@openscoring.io" aria-label="email">
            <img src="/assets/images/email_round.svg" width="48" height="48" alt="Contact Openscoring.IO">
          </a>
        </li>
        <li>
          <a href="https://twitter.com/openscoring" target="_blank" aria-label="twitter">
            <img src="/assets/images/twitter_round.svg" width="48" height="48" alt="Follow Openscoring.IO on Twitter">
          </a>
        </li>
      </ul>
    </div>
  </div>
</footer>

  <script>
    var sc_project = 11704106;
    var sc_security = "a7d1bf16";
    var sc_invisible = 1;
    var scJsHost = (("https:" == document.location.protocol) ?
      "https://secure." : "http://www.");
  </script>

  <script type="text/javascript" src="https://secure.statcounter.com/counter/counter.js" async=""></script>

  <noscript>
    <div class="statcounter">
      <a title="web analytics" href="https://statcounter.com/">
        <img class="statcounter" src="https://c.statcounter.com/11704106/0/a7d1bf16/1/" alt="web analytics" />
      </a>
    </div>
  </noscript>

  <script type="text/javascript" src="/assets/js/script.js" defer></script>
</body>

</html>