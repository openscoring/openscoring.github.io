<!DOCTYPE html>
<html lang=" en-US">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0" />
  <meta name="format-detection" content="telephone=no">
  <meta name="theme-color" content="#ffffff" />
  <meta name="msapplication-navbutton-color" content="#ffffff">
  <meta name="apple-mobile-web-app-status-bar-style" content="#ffffff">

  <meta name="description" content="">
  <meta name="keywords" content="scikit-learn scikit-lego sklearn2pmml">
  <meta name="author" content="vruusmann">

  <title>Extending Scikit-Learn with outlier detector transformer type - Openscoring</title>

  <meta name="robots" content="index, follow, max-snippet:-1, max-video-preview:-1, max-image-preview:large" />
  <link rel="canonical" href="https://openscoring.io/blog/2021/07/16/sklearn_outlier_detector_transformer/" />
  <meta property="og:locale" content="en_US" />
  <meta property="og:type" content="website" />
  <meta property="og:title" content="Extending Scikit-Learn with outlier detector transformer type - Openscoring" />
  <meta property="og:url" content="/blog/2021/07/16/sklearn_outlier_detector_transformer/" />
  <meta property="og:site_name" content="Openscoring" />
  <meta property="og:updated_time" content="2021-07-16 00:00:00 +0300" />
  <meta property="article:published_time" content="2021-07-16 00:00:00 +0300" />
  <meta property="article:modified_time" content="2021-07-16 00:00:00 +0300" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Extending Scikit-Learn with outlier detector transformer type - Openscoring" />
  <meta name="twitter:label1" content="Written by" />
  <meta name="twitter:data1" content="Villu Ruusmann" />
  <meta name="twitter:label2" content="Time to read" />
  <meta name="twitter:data2" content="Less than a minute" />

  <link rel="icon" href="/assets/images/fa-150x150.png" sizes="32x32" />
  <link rel="icon" href="/assets/images/fa.png" sizes="192x192" />
  <link rel="apple-touch-icon" href="/assets/images/fa.png" />
  <link rel="stylesheet" href="/assets/css/main.css">
  <meta name="msapplication-TileImage" content="h/assets/images/fa.png" />
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->
</head>

<body>
  <header class="header">
  <div class="container">
    <nav class="nav--main">
      <a class="logo" href="/" aria-label="home">
        <img src="/assets/images/logo.svg" alt="" width="35" height="32" loading="lazy">
        <span>Openscoring.IO</span>
      </a>

      <input type="checkbox" id="nav__toggle--main" class="nav__toggle">
      <label for="nav__toggle--main">Menu<span></span></label>

      <div class="menu">
        <ul id="menu--main">
          <li><a href="/#overview" aria-current="page">Overview</a></li>
          <li><a href="/#products" aria-current="page">Products</a></li>
          <li><a href="/#licensing" aria-current="page">Licensing</a></li>
          <li><a href="/#consulting" aria-current="page">Consulting</a></li>
        </ul>
      </div>

      <label for="nav__toggle--main" class="overlay"></label>

      <a href="/blog" class="btn btn--small">Blog</a>
    </nav>
  </div>
</header>

  <main class="container mt-26">
    <h1>Extending Scikit-Learn with outlier detector transformer type</h1>
  
<div class="post">
  <p>Outlier detection is a subfield of unsupervised learning, where the objective is to assign <strong>anomaly score</strong> to data records based on their feature values alone.
A data record is considered to be anomalous if it deviates from the average sample. For example, exhibiting extreme feature value(s), exhibiting an unusual combination of feature values, etc.</p>

<p>Scikit-Learn outlier detector classes inherit from the <code class="language-plaintext highlighter-rouge">sklearn.base.OutlierMixin</code> base class, which is completely separate from common estimator base classes such as <code class="language-plaintext highlighter-rouge">sklearn.base.(ClassifierMixin|RegressorMixin)</code> or <code class="language-plaintext highlighter-rouge">sklearn.base.TransformerMixin</code>.</p>

<p>Outlier detector classes are very similar to model classes API-wise, because the main “interaction point” is the <code class="language-plaintext highlighter-rouge">predict(X)</code> method.
The <code class="language-plaintext highlighter-rouge">predict(X)</code> method returns a bi-valued categorical integer, where the “outlier” and “inlier” categories are denoted by <code class="language-plaintext highlighter-rouge">-1</code> and <code class="language-plaintext highlighter-rouge">+1</code> values, respectively.
Some outlier detector classes may additionally define a <code class="language-plaintext highlighter-rouge">decision_function(X)</code> method, which returns the raw anomaly score as a continuous float.</p>

<p>The estimation of anomaly scores may be a valid end goal in and of itself:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">IsolationForest</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="n">transformer</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"cont"</span><span class="p">,</span> <span class="s">"passthrough"</span><span class="p">,</span> <span class="n">cont_columns</span><span class="p">),</span>
  <span class="p">(</span><span class="s">"cat"</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span> <span class="o">=</span> <span class="bp">False</span><span class="p">),</span> <span class="n">cat_columns</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">outlier_detector</span> <span class="o">=</span> <span class="n">IsolationForest</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">13</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"transformer"</span><span class="p">,</span> <span class="n">transformer</span><span class="p">),</span>
  <span class="p">(</span><span class="s">"outlier_detector"</span><span class="p">,</span> <span class="n">outlier_detector</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">pipeline</span><span class="p">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="anomaly-score-as-a-feature">Anomaly score as a feature</h3>

<p>A data scientist may wish to enrich the dataset with the anomaly score feature in order to train models that exhibit improved predictive performance, and are safer to deploy.
For example, implementing a row filterer based on anomaly score thresholding.</p>

<p>The training dataset should always be cleaned from anomalous data records to ensure that the learned model reflects a narrower and more consistent statistical hypothesis.</p>

<p>Validation and testing datasets may also be cleaned.
However, in some application scenarios it may be necessary to make the prediction for all data records in the dataset, but label them with an auxiliary quality information (eg. “reliable”, “unsure”, “not at all reliable” depending on how well the data record fits into the applicability domain of the model).</p>

<p>An outlier detector must be connected to a pipeline in a parallel way.
This is easily accomplished using the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html"><code class="language-plaintext highlighter-rouge">FeatureUnion</code></a> meta-transformer, which applies a list of transformers to the same input data matrix, and then concats their results column-wise.</p>

<p>If the input data matrix needs to be preserved unchanged, then one of the list elements must be an identity transformer.
Unfortunately, unlike many other Scikit-Learn meta-transformers, the <code class="language-plaintext highlighter-rouge">FeatureUnion</code> meta-transformer does not support using the “passthrough” instruction.</p>

<p>A reusable <code class="language-plaintext highlighter-rouge">sklego.preprocessing.IdentityTransformer</code> transformer can be found from the <a href="https://github.com/koaning/scikit-lego"><code class="language-plaintext highlighter-rouge">scikit-lego</code></a> package:</p>

<p>Making a feature matrix enricher:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">FeatureUnion</span>
<span class="kn">from</span> <span class="nn">sklego.preprocessing</span> <span class="kn">import</span> <span class="n">IdentityTransformer</span>

<span class="n">enricher</span> <span class="o">=</span> <span class="n">FeatureUnion</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"identity"</span><span class="p">,</span> <span class="n">IdentityTransformer</span><span class="p">()),</span>
  <span class="p">(</span><span class="s">"outlier_detector"</span><span class="p">,</span> <span class="n">outlier_detector</span><span class="p">)</span>
<span class="p">])</span>
</code></pre></div></div>

<p>The ordering of <code class="language-plaintext highlighter-rouge">FeatureUnion</code> list elements is not significant from the computational perspective.
It may be advisable to insert the identity transformer first and the outlier detector second, in order to avoid messing up the original feature indices.</p>

<p>Integrating the feature matrix enricher into a (supervised learning-) pipeline:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"transformer"</span><span class="p">,</span> <span class="n">transformer</span><span class="p">),</span>
  <span class="p">(</span><span class="s">"enricher"</span><span class="p">,</span> <span class="n">enricher</span><span class="p">),</span>
  <span class="p">(</span><span class="s">"classifier"</span><span class="p">,</span> <span class="n">classifier</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">pipeline</span><span class="p">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<p>It turns out that the above pipeline cannot be executed, because Scikit-Learn expects all estimators except for the final estimator to declare a <code class="language-plaintext highlighter-rouge">transform(X)</code> method.</p>

<p>Python error:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py", line 63, in inner_f
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.7/site-packages/sklearn/pipeline.py", line 846, in __init__
    self._validate_transformers()
  File "/usr/local/lib/python3.7/site-packages/sklearn/pipeline.py", line 896, in _validate_transformers
    (t, type(t)))
TypeError: All estimators should implement fit and transform. 'IsolationForest(random_state=13)' (type &lt;class 'sklearn.ensemble._iforest.IsolationForest'&gt;) doesn't
</code></pre></div></div>

<p>The solution is to “masquerade” the outlier detector as a transformer.</p>

<p>This can be accomplished in two ways.
First, if the outlier detector class can be changed, then it can be made to inherit both from <code class="language-plaintext highlighter-rouge">OutlierMixin</code> and <code class="language-plaintext highlighter-rouge">TransformerMixin</code> base classes.
Most outlier detectors are very good candidates for becoming transformers, because they implement unsupervised learning algorithms that ignore the label column (ie. assume <code class="language-plaintext highlighter-rouge">fit(X, y = None)</code>).</p>

<p>Second, the outlier detector can be wrapped into a general-purpose “estimator-as-transformer” transformer, which connects wrapper’s <code class="language-plaintext highlighter-rouge">transform(X, y)</code> method to wrappee’s <code class="language-plaintext highlighter-rouge">predict(X)</code> or <code class="language-plaintext highlighter-rouge">decision_function(X)</code> method.</p>

<p>Quick search reveals that such classes are plentiful in existence.
It makes sense to pick the <code class="language-plaintext highlighter-rouge">sklego.meta.EstimatorTransformer</code> meta-transformer from the <code class="language-plaintext highlighter-rouge">scikit-lego</code> package again, because it is functionally adequate, and this exercise already has this package dependency.</p>

<p>Making a feature matrix enricher that is fully compatible with Scikit-Learn transformer API:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklego.meta</span> <span class="kn">import</span> <span class="n">EstimatorTransformer</span>

<span class="n">enricher</span> <span class="o">=</span> <span class="n">FeatureUnion</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"identity"</span><span class="p">,</span> <span class="n">IdentityTransformer</span><span class="p">()),</span>
  <span class="p">(</span><span class="s">"outlier_detector"</span><span class="p">,</span> <span class="n">EstimatorTransformer</span><span class="p">(</span><span class="n">outlier_detector</span><span class="p">,</span> <span class="n">predict_func</span> <span class="o">=</span> <span class="s">"decision_function"</span><span class="p">))</span>
<span class="p">])</span>
</code></pre></div></div>

<p>If the outlier detector is operated in “labelling mode” (by invoking the <code class="language-plaintext highlighter-rouge">predict(X)</code> method that returns a bi-valued categorical integer feature, see above), then it is advisable to explicitly encode it in order to avoid accidental type system violations.</p>

<p>For example, linear models accept a categorical integer feature, but cast it forcibly to a continuous float feature. During training, the categorical integer feature is associated with a single beta coefficient.
Such beta coefficient lacks deeper meaning, because it suggests that the contribution and significance of outliers (ie. the <code class="language-plaintext highlighter-rouge">-1</code> category level) is the exact opposite of inliers (ie. the <code class="language-plaintext highlighter-rouge">+1</code> category level).</p>

<p>If the categorical integer value is one-hot-encoded (similar to raw categorical features) then each category level becomes associated with a separate beta coefficient instead. More importantly, the effect of the numeric value of the categorical integer feature is eliminated.</p>

<p>Improving the feature matrix enricher for the “labelling mode”  use case:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklego.meta</span> <span class="kn">import</span> <span class="n">EstimatorTransformer</span>

<span class="n">enricher</span> <span class="o">=</span> <span class="n">FeatureUnion</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"identity"</span><span class="p">,</span> <span class="n">IdentityTransformer</span><span class="p">()),</span>
  <span class="c1">#("outlier_detector", EstimatorTransformer(outlier_detector, predict_func = "decision_function"))
</span>  <span class="p">(</span><span class="s">"outlier_detector"</span><span class="p">,</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">EstimatorTransformer</span><span class="p">(</span><span class="n">outlier_detector</span><span class="p">,</span> <span class="n">predict_func</span> <span class="o">=</span> <span class="s">"predict"</span><span class="p">),</span> <span class="n">OneHotEncoder</span><span class="p">()))</span>
<span class="p">])</span>
</code></pre></div></div>

<h3 id="conditional-execution-of-estimators">Conditional execution of estimators</h3>

<p>The <a href="https://github.com/jpmml/sklearn2pmml"><code class="language-plaintext highlighter-rouge">sklearn2pmml</code></a> package provides <code class="language-plaintext highlighter-rouge">sklearn2pmml.ensemble.SelectFirstClassifier</code> and <code class="language-plaintext highlighter-rouge">sklearn2pmml.ensemble.SelectFirstClassifier</code> ensemble models, which can be used to implement row filtering based on anomaly score.</p>

<p>By analogy with <code class="language-plaintext highlighter-rouge">ColumnTransformer</code>, their constructors take a list of <code class="language-plaintext highlighter-rouge">(name, estimator, predicate)</code> tuples.
A “select first” estimator partitions the incoming dataset into subsets based on which predicate (ie. a boolean expression) first evaluates to <code class="language-plaintext highlighter-rouge">True</code> value for a data record. All the actual training and prediction work is then delegated to child estimators.</p>

<p>Making a “select first” classifier that partitions the dataset into “outlier” and “inlier” subsets based on the raw anomaly score:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn2pmml.ensemble</span> <span class="kn">import</span> <span class="n">SelectFirstClassifier</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">SelectFirstClassifier</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"outlier"</span><span class="p">,</span> <span class="n">outlier_classifier</span><span class="p">,</span> <span class="s">"X[-1] &lt;= 0"</span><span class="p">),</span>
  <span class="p">(</span><span class="s">"inlier"</span><span class="p">,</span> <span class="n">inlier_classifier</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="bp">True</span><span class="p">))</span>
<span class="p">])</span>
</code></pre></div></div>

<p>By convention, during row filtering, each data record is exposed as a row vector variable called <code class="language-plaintext highlighter-rouge">X</code>.</p>

<p>The predicate for the “outlier” subset is specified as <code class="language-plaintext highlighter-rouge">X[-1] &lt;= 0</code>.
The left-hand side <code class="language-plaintext highlighter-rouge">X[-1]</code> reads “get the value of the last row vector element”.
The extended right-hand side <code class="language-plaintext highlighter-rouge">&lt;= 0</code> reads “test if this value is negative”. This condition has been extracted from the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html#sklearn.ensemble.IsolationForest.predict"><code class="language-plaintext highlighter-rouge">IsolationForest.predict(X)</code></a> method, and is fairly specific to it.
When using a different outlier detector, a different comparison operator and/or a different threshold value may be more appropriate.</p>

<p>The predicate for the “inlier” subset is simply a <code class="language-plaintext highlighter-rouge">True</code> constant.
Its intention is to “match everything (that has not been matched by previous predicates)”.</p>

<p>Child estimators see different rows but identical columns.
It is fine to dispatch the raw anomaly score to the “outlier” child estimator. In fact, the magnitude of this feature might be highly significant in explaining the variance between data records.</p>

<p>However, this feature should be withdrawn from the “inlier” child estimator, because, by definition, this subset is free from anomalous data records.</p>

<p>Emulating column dropping functionality using the <code class="language-plaintext highlighter-rouge">ColumnTransformer</code> meta-transformer:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">make_column_dropper</span><span class="p">(</span><span class="n">drop_cols</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">ColumnTransformer</span><span class="p">([</span>
    <span class="p">(</span><span class="s">"drop"</span><span class="p">,</span> <span class="s">"drop"</span><span class="p">,</span> <span class="n">drop_cols</span><span class="p">)</span>
  <span class="p">],</span> <span class="n">remainder</span> <span class="o">=</span> <span class="s">"passthrough"</span><span class="p">)</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">SelectFirstClassifier</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"outlier"</span><span class="p">,</span> <span class="n">outlier_classifier</span><span class="p">,</span> <span class="s">"X[-1] &lt;= 0"</span><span class="p">),</span>
  <span class="p">(</span><span class="s">"inlier"</span><span class="p">,</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">make_column_dropper</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">inlier_classifier</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="bp">True</span><span class="p">))</span>
<span class="p">])</span>
</code></pre></div></div>

<p>All the presented estimators lend themselves to conversion to the PMML representation using the <code class="language-plaintext highlighter-rouge">sklearn2pmml</code> package.</p>

<p>Assembling the final pipeline, and converting it to a PMML document:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn2pmml</span> <span class="kn">import</span> <span class="n">sklearn2pmml</span>
<span class="kn">from</span> <span class="nn">sklearn2pmml.pipeline</span> <span class="kn">import</span> <span class="n">PMMLPipeline</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">PMMLPipeline</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"transformer"</span><span class="p">,</span> <span class="n">transformer</span><span class="p">),</span>
  <span class="p">(</span><span class="s">"enricher"</span><span class="p">,</span> <span class="n">enricher</span><span class="p">),</span>
  <span class="p">(</span><span class="s">"classifier"</span><span class="p">,</span> <span class="n">classifier</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">sklearn2pmml</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="s">"SelectFirstAudit.pmml"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="resources">Resources</h3>

<ul>
  <li>“Audit” dataset: <a href="https://openscoring.io/resources/data/audit.csv"><code class="language-plaintext highlighter-rouge">audit.csv</code></a></li>
  <li>Python script: <a href="https://openscoring.io/resources/2021-07-16/train.py"><code class="language-plaintext highlighter-rouge">train.py</code></a></li>
</ul>

</div>



  </main>

  <footer class="footer">
  <div class="container">
    <div class="mb-6">© 2022 - Openscoring.IO</div>

    <div class="mb-6">
      <ul class="flex gap-4 list-none">
        <li>
          <a href="mailto:info@openscoring.io" aria-label="email">
            <img src="/assets/images/email_round.svg" width="48" height="48" alt="Contact Openscoring.IO">
          </a>
        </li>
        <li>
          <a href="https://twitter.com/openscoring" target="_blank" aria-label="twitter">
            <img src="/assets/images/twitter_round.svg" width="48" height="48" alt="Follow Openscoring.IO on Twitter">
          </a>
        </li>
      </ul>
    </div>
  </div>
</footer>

  <script>
    var sc_project = 11704106;
    var sc_security = "a7d1bf16";
    var sc_invisible = 1;
    var scJsHost = (("https:" == document.location.protocol) ?
      "https://secure." : "http://www.");
  </script>

  <script type="text/javascript" src="https://secure.statcounter.com/counter/counter.js" async=""></script>

  <noscript>
    <div class="statcounter">
      <a title="web analytics" href="https://statcounter.com/">
        <img class="statcounter" src="https://c.statcounter.com/11704106/0/a7d1bf16/1/" alt="web analytics" />
      </a>
    </div>
  </noscript>

  <script type="text/javascript" src="/assets/js/script.js" defer></script>
</body>

</html>