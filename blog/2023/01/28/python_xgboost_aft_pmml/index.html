<!DOCTYPE html>
<html lang="en">

<head>
  <script src="https://www.googletagmanager.com/gtag/js?id=G-1XC1KCZX17" async></script>

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'G-1XC1KCZX17');
</script>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0">
  <meta name="format-detection" content="telephone=no">
  <meta name="theme-color" content="#ffffff">
  <meta name="msapplication-navbutton-color" content="#ffffff">
  <meta name="apple-mobile-web-app-status-bar-style" content="#ffffff">

  <meta name="description" content="">
  <meta name="keywords" content="scikit-learn xgboost sklearn2pmml data-categorical data-missing">
  <meta name="author" content="vruusmann">

  <title>Training Python-based XGBoost accelerated failure time models - Openscoring</title>

  <meta name="robots" content="index, follow, max-snippet:-1, max-video-preview:-1, max-image-preview:large">
  <link rel="canonical" href="https://openscoring.io/blog/2023/01/28/python_xgboost_aft_pmml/">
  <meta property="og:locale" content="en_US">
  <meta property="og:type" content="website">
  <meta property="og:title" content="Training Python-based XGBoost accelerated failure time models - Openscoring">
  <meta property="og:url" content="/blog/2023/01/28/python_xgboost_aft_pmml/">
  <meta property="og:site_name" content="Openscoring">
  <meta property="og:updated_time" content="2023-01-28 00:00:00 +0200">
  <meta property="article:published_time" content="2023-01-28 00:00:00 +0200">
  <meta property="article:modified_time" content="2023-01-28 00:00:00 +0200">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Training Python-based XGBoost accelerated failure time models - Openscoring">
  <meta name="twitter:label1" content="Written by">
  <meta name="twitter:data1" content="Villu Ruusmann">
  <meta name="twitter:label2" content="Time to read">
  <meta name="twitter:data2" content="Less than a minute">

  <link rel="icon" href="/assets/images/fa-150x150.png" sizes="32x32">
  <link rel="icon" href="/assets/images/fa.png" sizes="192x192">
  <link rel="apple-touch-icon" href="/assets/images/fa.png">
  <link rel="stylesheet" href="/assets/css/main.css">
  <meta name="msapplication-TileImage" content="h/assets/images/fa.png">
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->
</head>

<body>
  <header class="header">
  <div class="container">
    <nav class="nav--main">
      <a class="logo" href="/" aria-label="home">
        <img src="/assets/images/logo.svg" alt="" width="35" height="32" loading="lazy">
        <span>Openscoring</span>
      </a>

      <input type="checkbox" id="nav__toggle--main" class="nav__toggle">
      <label for="nav__toggle--main">Menu<span></span></label>

      <div class="menu">
        <ul id="menu--main">
          <li><a href="/#overview" aria-current="page">Overview</a></li>
          <li><a href="/#products" aria-current="page">Products</a></li>
          <li><a href="/#licensing" aria-current="page">Licensing</a></li>
          <li><a href="/#consulting" aria-current="page">Consulting</a></li>
        </ul>
      </div>

      <label for="nav__toggle--main" class="overlay"></label>

      <a href="/blog/" class="btn btn--small">Blog</a>
    </nav>
  </div>
</header>

  <main class="container mt-26">
    <h1>Training Python-based XGBoost accelerated failure time models</h1>
  
<div class="post">
  <p>Survival analysis is a subtype of regression analysis, which models time durations (eg. time to an event of interest).</p>

<p>XGBoost supports both Cox proportional hazards (Cox PH) and accelerated failure time (AFT) algorithms.
The training is currently possible via the low-level <a href="https://xgboost.readthedocs.io/en/stable/python/python_api.html#module-xgboost.training">Python Learning API</a>, but not via the high-level <a href="https://xgboost.readthedocs.io/en/stable/python/python_api.html#module-xgboost.sklearn">Scikit-Learn API</a>.
This limitation can be tracked as <a href="https://github.com/dmlc/xgboost/issues/7292">XGBoost-7292</a>.</p>

<p>The solution is to train XGBoost survival models using the Python Learning API, and then migrate them to the Scikit-Learn API for deployment.</p>

<h2 id="data-canonicalization">Data canonicalization</h2>

<p>Loading the <a href="https://lifelines.readthedocs.io/en/latest/lifelines.datasets.html#lifelines.datasets.load_lung">“lung” dataset</a>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">lifelines.datasets</span> <span class="kn">import</span> <span class="n">load_lung</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">load_lung</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">dtypes</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">isna</span><span class="p">().</span><span class="nb">sum</span><span class="p">())</span>
</code></pre></div></div>

<p>The loaded data matrix contains ten numeric columns:</p>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Role</th>
      <th>Loaded <code class="language-plaintext highlighter-rouge">dtype</code></th>
      <th>Refined <code class="language-plaintext highlighter-rouge">dtype</code></th>
      <th>Missing</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">inst</code></td>
      <td>feature</td>
      <td><code class="language-plaintext highlighter-rouge">float64</code></td>
      <td><code class="language-plaintext highlighter-rouge">pandas.Int64Dtype</code></td>
      <td>1</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">time</code></td>
      <td>proto-label</td>
      <td><code class="language-plaintext highlighter-rouge">int64</code></td>
      <td><code class="language-plaintext highlighter-rouge">int64</code></td>
      <td>0</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">status</code></td>
      <td>proto-label</td>
      <td><code class="language-plaintext highlighter-rouge">int64</code></td>
      <td><code class="language-plaintext highlighter-rouge">int64</code></td>
      <td>0</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">age</code></td>
      <td>feature</td>
      <td><code class="language-plaintext highlighter-rouge">int64</code></td>
      <td><code class="language-plaintext highlighter-rouge">int64</code></td>
      <td>0</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">sex</code></td>
      <td>feature</td>
      <td><code class="language-plaintext highlighter-rouge">int64</code></td>
      <td><code class="language-plaintext highlighter-rouge">int64</code></td>
      <td>0</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">ph.ecog</code></td>
      <td>feature</td>
      <td><code class="language-plaintext highlighter-rouge">float64</code></td>
      <td><code class="language-plaintext highlighter-rouge">pandas.Int64Dtype</code></td>
      <td>1</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">ph.karno</code></td>
      <td>feature</td>
      <td><code class="language-plaintext highlighter-rouge">float64</code></td>
      <td><code class="language-plaintext highlighter-rouge">pandas.Int64Dtype</code></td>
      <td>1</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">pat.karno</code></td>
      <td>feature</td>
      <td><code class="language-plaintext highlighter-rouge">float64</code></td>
      <td><code class="language-plaintext highlighter-rouge">pandas.Int64Dtype</code></td>
      <td>3</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">meal.cal</code></td>
      <td>feature</td>
      <td><code class="language-plaintext highlighter-rouge">float64</code></td>
      <td><code class="language-plaintext highlighter-rouge">pandas.Int64Dtype</code></td>
      <td>47</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">wt.loss</code></td>
      <td>feature</td>
      <td><code class="language-plaintext highlighter-rouge">float64</code></td>
      <td><code class="language-plaintext highlighter-rouge">pandas.Int64Dtype</code></td>
      <td>14</td>
    </tr>
  </tbody>
</table>

<p>The <code class="language-plaintext highlighter-rouge">time</code> and <code class="language-plaintext highlighter-rouge">status</code> columns encode time durations, leaving the other eight columns as features.</p>

<p>All feature data are inherently integer-like. However, they are stored in <code class="language-plaintext highlighter-rouge">float64</code> data type columns in order to accommodate missing value placeholders in the form of <code class="language-plaintext highlighter-rouge">float("NaN")</code>.</p>

<p>Refining column data types:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">Int64Dtype</span>

<span class="n">cols</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
  <span class="n">has_missing</span> <span class="o">=</span> <span class="n">pandas</span><span class="p">.</span><span class="n">isnull</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]).</span><span class="nb">any</span><span class="p">()</span>
  <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="n">Int64Dtype</span><span class="p">()</span> <span class="k">if</span> <span class="n">has_missing</span> <span class="k">else</span> <span class="nb">int</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="data-pre-processing">Data pre-processing</h2>

<p>XGBoost versions 1.5 and newer can work with the canonicalized “lung” dataset as-is.
There is no longer any technical reason for imputing missing values or encoding categorical values.</p>

<p>In fact, this is a welcome development, as Scikit-Learn is rather inept at transforming sparse categorical features into legacy XGBoost-compatible representation, as discussed in detail in an earlier blog post about <a href="/blog/2022/04/12/onehot_encoding_sklearn_xgboost_pipeline/">one-hot encoding categorical features in Scikit-Learn XGBoost pipelines</a>.</p>

<p>The only data pre-processing action that is needed is casting the data type of <code class="language-plaintext highlighter-rouge">inst</code> and <code class="language-plaintext highlighter-rouge">sex</code> columns from integer to <a href="https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.html"><code class="language-plaintext highlighter-rouge">pandas.CategoricalDtype</code></a>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="s">"inst"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"inst"</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"sex"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"sex"</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span>
</code></pre></div></div>

<p>However, the above code is not suitable for deployment!</p>

<p>A quick cast using the <code class="language-plaintext highlighter-rouge">category</code> data type alias creates a new <code class="language-plaintext highlighter-rouge">CategoricalDtype</code> object on each and every call.
Its “business state” is a mapping from category levels to category indices.
If a testing dataset does not have exactly the same set of unique category levels as the training dataset, then the mapping will be different, and along with it all the predictions.</p>

<p>Constructing a casting transformer that is robust towards dataset variations:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">CategoricalDtype</span>
<span class="kn">from</span> <span class="nn">sklearn_pandas</span> <span class="kn">import</span> <span class="n">DataFrameMapper</span>
<span class="kn">from</span> <span class="nn">sklearn2pmml.decoration</span> <span class="kn">import</span> <span class="n">CategoricalDomain</span><span class="p">,</span> <span class="n">ContinuousDomain</span>

<span class="n">cat_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s">"inst"</span><span class="p">,</span> <span class="s">"sex"</span><span class="p">]</span>
<span class="n">cont_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s">"age"</span><span class="p">,</span> <span class="s">"ph.ecog"</span><span class="p">,</span> <span class="s">"ph.karno"</span><span class="p">,</span> <span class="s">"pat.karno"</span><span class="p">,</span> <span class="s">"meal.cal"</span><span class="p">,</span> <span class="s">"wt.loss"</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">make_cat_dtype</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="n">categories</span> <span class="o">=</span> <span class="n">pandas</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="c1"># Drop null-like category levels
</span>  <span class="n">categories</span> <span class="o">=</span> <span class="n">numpy</span><span class="p">.</span><span class="n">delete</span><span class="p">(</span><span class="n">categories</span><span class="p">,</span> <span class="n">pandas</span><span class="p">.</span><span class="n">isnull</span><span class="p">(</span><span class="n">categories</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">CategoricalDtype</span><span class="p">(</span><span class="n">categories</span> <span class="o">=</span> <span class="n">categories</span><span class="p">,</span> <span class="n">ordered</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="n">inst_dtype</span> <span class="o">=</span> <span class="n">make_cat_dtype</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"inst"</span><span class="p">])</span>
<span class="n">sex_dtype</span> <span class="o">=</span> <span class="n">make_cat_dtype</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"sex"</span><span class="p">])</span>

<span class="n">transformer</span> <span class="o">=</span> <span class="n">DataFrameMapper</span><span class="p">(</span>
  <span class="p">[([</span><span class="s">"inst"</span><span class="p">],</span> <span class="n">CategoricalDomain</span><span class="p">(</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">inst_dtype</span><span class="p">))]</span> <span class="o">+</span>
  <span class="p">[([</span><span class="s">"sex"</span><span class="p">],</span> <span class="n">CategoricalDomain</span><span class="p">(</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">sex_dtype</span><span class="p">))]</span> <span class="o">+</span>
  <span class="p">[([</span><span class="n">cont_col</span><span class="p">],</span> <span class="n">ContinuousDomain</span><span class="p">(</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">numpy</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span> <span class="k">for</span> <span class="n">cont_col</span> <span class="ow">in</span> <span class="n">cont_cols</span><span class="p">]</span>
<span class="p">,</span> <span class="n">input_df</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">df_out</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>The cast to <code class="language-plaintext highlighter-rouge">CategoricalDtype</code> data type is performed using the <code class="language-plaintext highlighter-rouge">sklearn2pmml.decoration.CategoricalDomain</code> decorator. Alternatively, it could be performed using the <code class="language-plaintext highlighter-rouge">sklearn2pmml.preprocessing.CastTransformer</code> transformer.
Using decorators is preferable, because they capture valuable metadata about the training dataset (valid value space, univariate statistics, etc.) which serves as model documentation.</p>

<p>This cast is possible with Pandas’ data containers (eg. <code class="language-plaintext highlighter-rouge">pandas.DataFrame</code> and <code class="language-plaintext highlighter-rouge">pandas.Series</code>), but not with Numpy arrays and matrices.</p>

<p>The propagation of Pandas’ data containers through Scikit-Learn pipeline has been challenging.
Scikit-Learn version 1.2.0 introduces the <a href="https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_set_output.html">set_output API</a>, which allows to configure the output data container type for all transformer subclasses using the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html#sklearn.base.TransformerMixin.set_output"><code class="language-plaintext highlighter-rouge">TransformerMixin.set_output(transform)</code></a> method.</p>

<p>It will take some time until the set_output API gets propagated through the ecosystem.
Until then, the tried and tested <code class="language-plaintext highlighter-rouge">sklearn_pandas.DataFrameMapper</code> meta-transformer class is the way to go.</p>

<p>Unlike categorical features, continuous features do not require any casting or transformation here.
Nevertheless, they are also filtered through the <code class="language-plaintext highlighter-rouge">sklearn2pmml.decoration.ContinuousDomain</code> decorator in order to capture metadata.</p>

<p>In the above example, all columns are declared one by one, even if the associated transformation supports multi-column input.
This is needed for preserving the original column names.</p>

<p>Re-coding the label as pairs of scalar values:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">make_aft_label</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">status</span><span class="p">):</span>
  <span class="n">time_lower</span> <span class="o">=</span> <span class="n">time</span>

  <span class="n">time_upper</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
  <span class="n">time_upper</span><span class="p">[</span><span class="n">status</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">"+Inf"</span><span class="p">)</span>

  <span class="k">return</span> <span class="p">(</span><span class="n">time_lower</span><span class="p">,</span> <span class="n">time_upper</span><span class="p">)</span>
</code></pre></div></div>

<p>According to XGBoost conventions, uncensored labels are encoded as <code class="language-plaintext highlighter-rouge">(&lt;value&gt;, &lt;value&gt;)</code>, whereas right-censored labels are encoded as <code class="language-plaintext highlighter-rouge">(&lt;value&gt;, +Inf)</code>.</p>

<h2 id="training-via-python-learning-api">Training via Python Learning API</h2>

<p>Constructing an <a href="https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.DMatrix"><code class="language-plaintext highlighter-rouge">xgboost.DMatrix</code></a> object:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">DMatrix</span>

<span class="n">Xt</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">time_lower</span><span class="p">,</span> <span class="n">time_upper</span> <span class="o">=</span> <span class="n">make_aft_label</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"time"</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">"status"</span><span class="p">])</span>

<span class="n">dmat</span> <span class="o">=</span> <span class="n">DMatrix</span><span class="p">(</span>
  <span class="c1"># Features
</span>  <span class="n">data</span> <span class="o">=</span> <span class="n">Xt</span><span class="p">,</span>
  <span class="c1"># Label
</span>  <span class="n">label_lower_bound</span> <span class="o">=</span> <span class="n">time_lower</span><span class="p">,</span> <span class="n">label_upper_bound</span> <span class="o">=</span> <span class="n">time_upper</span><span class="p">,</span>
  <span class="n">missing</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">"NaN"</span><span class="p">),</span> 
  <span class="n">enable_categorical</span> <span class="o">=</span> <span class="bp">True</span>
<span class="p">)</span>
</code></pre></div></div>

<p>Training an <a href="https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.Booster"><code class="language-plaintext highlighter-rouge">xgboost.Booster</code></a> object, and saving it in JSON data format:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">xgboost</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">"objective"</span> <span class="p">:</span> <span class="s">"survival:aft"</span><span class="p">,</span>
  <span class="s">"eval_metric"</span> <span class="p">:</span> <span class="s">"aft-nloglik"</span><span class="p">,</span>
  <span class="s">"max_depth"</span> <span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
  <span class="s">"tree_method"</span> <span class="p">:</span> <span class="s">"hist"</span>
<span class="p">}</span>

<span class="n">booster</span> <span class="o">=</span> <span class="n">xgboost</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span><span class="p">,</span> <span class="n">dtrain</span> <span class="o">=</span> <span class="n">dmat</span><span class="p">,</span> <span class="n">num_boost_round</span> <span class="o">=</span> <span class="mi">31</span><span class="p">)</span>
<span class="n">booster</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="s">"booster.json"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Important</strong>: The computation of categorical splits must be activated by setting the <a href="https://xgboost.readthedocs.io/en/stable/treemethod.html"><code class="language-plaintext highlighter-rouge">tree_method</code> tree param</a> to some approximated training algorithm such as <code class="language-plaintext highlighter-rouge">approx</code> or <code class="language-plaintext highlighter-rouge">hist</code> (<code class="language-plaintext highlighter-rouge">gpu_hist</code> on GPU implementations).
If this tree param is set to <code class="language-plaintext highlighter-rouge">exact</code> (default for small datasets such as the “lung” dataset), then the computation yields continuous splits, irrespective of the underlying data type.
XGBoost does not issue any warnings about the fallback.</p>

<p>When in doubt, it is possible to open the booster JSON file in a text editor, and skim over <code class="language-plaintext highlighter-rouge">categories_nodes</code>, <code class="language-plaintext highlighter-rouge">categories_segments</code> and <code class="language-plaintext highlighter-rouge">categories_sizes</code> properties.
With categorical features around, one would expect to see a healthy proportion of non-empty list values.
It would be a clear cause for concern if they were all empty.</p>

<h2 id="making-predictions-via-scikit-learn-api">Making predictions via Scikit-Learn API</h2>

<p>Scikit-Learn pipeline is a composite of transformers and estimators.
It provides atomic pickling, and unified <code class="language-plaintext highlighter-rouge">fit_transform(X)</code> and <code class="language-plaintext highlighter-rouge">fit_predict(X, y)</code> API methods for dealing with arbitrary complexity workflows.</p>

<p>Constructing a pipeline from available components:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">Booster</span>
<span class="kn">from</span> <span class="nn">xgboost.sklearn</span> <span class="kn">import</span> <span class="n">XGBRegressor</span>

<span class="n">regressor</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">()</span>
<span class="n">regressor</span><span class="p">.</span><span class="n">_Booster</span> <span class="o">=</span> <span class="n">Booster</span><span class="p">(</span><span class="n">model_file</span> <span class="o">=</span> <span class="s">"booster.json"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
  <span class="p">(</span><span class="s">"transformer"</span><span class="p">,</span> <span class="n">transformer</span><span class="p">),</span>
  <span class="p">(</span><span class="s">"regressor"</span><span class="p">,</span> <span class="n">regressor</span><span class="p">)</span>
<span class="p">])</span>
</code></pre></div></div>

<p>As noted earlier, survival analysis is a subtype of regression analysis.
This makes it possible to wrap an AFT booster object into an <code class="language-plaintext highlighter-rouge">xgboost.XGBRegressor</code> object, and have it directly respond to <code class="language-plaintext highlighter-rouge">XGBRegressor.predict(X)</code> method calls.</p>

<h2 id="pipeline-verification">Pipeline verification</h2>

<p>Typically, a <code class="language-plaintext highlighter-rouge">Pipeline</code> object is constructed using unfitted components, and fitted right thereafter. This is convenient and makes a very strong guarantee that all pipeline steps work together harmoniously.
However, there are still plenty of situations where one or more pipeline steps defy the unified API, or make use of extra information or functionality that is not available within the <code class="language-plaintext highlighter-rouge">Pipeline.fit(X, y)</code> method scope.</p>

<p>When a <code class="language-plaintext highlighter-rouge">Pipeline</code> object is constructed from pre-fitted components, then there are no guarantees in place. For example, the <code class="language-plaintext highlighter-rouge">Pipeline</code> constructor does not even check if the output dimensions of one step match the input dimensions of the next step.</p>

<p>The correctness of unknown origin and unknown status <code class="language-plaintext highlighter-rouge">Pipeline</code> objects can only be assessed empirically, by calling their predict methods (eg. <code class="language-plaintext highlighter-rouge">predict(X)</code>, <code class="language-plaintext highlighter-rouge">predict_proba(X)</code>) with adequate verification datasets, and comparing actual results against expected results.</p>

<p>Asserting equivalence between Python Learning API and Scikit-Learn API predictions:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">check_predict</span><span class="p">(</span><span class="n">expected</span><span class="p">,</span> <span class="n">actual</span><span class="p">,</span> <span class="n">rtol</span><span class="p">,</span> <span class="n">atol</span><span class="p">):</span>
  <span class="n">isclose</span> <span class="o">=</span> <span class="n">numpy</span><span class="p">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">expected</span><span class="p">,</span> <span class="n">actual</span><span class="p">,</span> <span class="n">rtol</span> <span class="o">=</span> <span class="n">rtol</span><span class="p">,</span> <span class="n">atol</span> <span class="o">=</span> <span class="n">atol</span><span class="p">,</span> <span class="n">equal_nan</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
  <span class="n">num_conflicts</span> <span class="o">=</span> <span class="n">numpy</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">isclose</span> <span class="o">==</span> <span class="bp">False</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">num_conflicts</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">status</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">isclose</span><span class="p">):</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">status</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"{} != {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">expected</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">actual</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
    <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">"Found {} conflicting prediction(s)"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">num_conflicts</span><span class="p">))</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"All correct"</span><span class="p">)</span>

<span class="c1"># Reference values
</span><span class="n">booster_time</span> <span class="o">=</span> <span class="n">booster</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dmat</span><span class="p">)</span>

<span class="c1"># To-be-checked values
</span><span class="n">pipeline_time</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">check_predict</span><span class="p">(</span><span class="n">booster_time</span><span class="p">,</span> <span class="n">pipeline_time</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">)</span>
</code></pre></div></div>

<p>The AFT booster object makes predictions using the same <code class="language-plaintext highlighter-rouge">DMatrix</code> object that it was fitted on, whereas the pipeline object makes predictions starting from the canonicalized dataset.
If there were any discrepancies between their predictions, then it would be natural to put more trust in the former (the “expected” side), and less in the latter (the “actual” side).</p>

<p>Arrays of floating-point numeric values can be compared element-wise for equivalence using the <a href="https://numpy.org/doc/stable/reference/generated/numpy.isclose.html"><code class="language-plaintext highlighter-rouge">numpy.isclose</code></a> utility function.</p>

<p>The algorithm is controlled by two parameters.
First, relative tolerance (the <code class="language-plaintext highlighter-rouge">rtol</code> argument) is a workflow property (the precision of the default numeric data type, plus the order of “mathematical complexity” of transformations).
Second, absolute tolerance (the <code class="language-plaintext highlighter-rouge">atol</code> argument) is a dataset property.</p>

<p>XGBoost is based on <code class="language-plaintext highlighter-rouge">float32</code> data type, which limits the relative tolerance to about <code class="language-plaintext highlighter-rouge">1E-6 .. 1E-7</code> range.</p>

<p>The label of the “lung” dataset is survival time in days, with a typical range from 100 to 2000.
The absolute tolerance value of <code class="language-plaintext highlighter-rouge">1E-3</code> is estimated by multiplying the selected relative tolerance <code class="language-plaintext highlighter-rouge">1E-6</code> with the selected characteristic label value of <code class="language-plaintext highlighter-rouge">1000</code>.</p>

<p>In other words, two survival times are considered to be equivalent if they agree with each other in the order of “full minutes or better”.</p>

<h2 id="pmml">PMML</h2>

<p>Wrapping the pipeline object into a <code class="language-plaintext highlighter-rouge">PMMLPipeline</code> object:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn2pmml</span> <span class="kn">import</span> <span class="n">make_pmml_pipeline</span><span class="p">,</span> <span class="n">sklearn2pmml</span>

<span class="n">pmml_pipeline</span> <span class="o">=</span> <span class="n">make_pmml_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">active_fields</span> <span class="o">=</span> <span class="p">(</span><span class="n">cat_cols</span> <span class="o">+</span> <span class="n">cont_cols</span><span class="p">),</span> <span class="n">target_fields</span> <span class="o">=</span> <span class="p">[</span><span class="s">"time"</span><span class="p">])</span>

<span class="n">Xt_imp</span> <span class="o">=</span> <span class="n">booster</span><span class="p">.</span><span class="n">get_score</span><span class="p">(</span><span class="n">importance_type</span> <span class="o">=</span> <span class="s">"weight"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">Xt_imp</span><span class="p">)</span>

<span class="c1"># Transform dict to list
</span><span class="n">Xt_imp</span> <span class="o">=</span> <span class="p">[</span><span class="n">Xt_imp</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">pmml_pipeline</span><span class="p">.</span><span class="n">active_fields</span><span class="p">]</span>

<span class="n">regressor</span><span class="p">.</span><span class="n">pmml_feature_importances_</span> <span class="o">=</span> <span class="n">numpy</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Xt_imp</span><span class="p">)</span>

<span class="n">df_verif</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">pmml_pipeline</span><span class="p">.</span><span class="n">active_fields</span><span class="p">].</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="n">pmml_pipeline</span><span class="p">.</span><span class="n">verify</span><span class="p">(</span><span class="n">df_verif</span><span class="p">,</span> <span class="n">precision</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="n">zeroThreshold</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">)</span>

<span class="n">sklearn2pmml</span><span class="p">(</span><span class="n">pmml_pipeline</span><span class="p">,</span> <span class="s">"XGBoostAFTLung.pmml"</span><span class="p">)</span>
</code></pre></div></div>

<p>It is advisable to use the <code class="language-plaintext highlighter-rouge">sklearn2pmml.make_pmml_pipeline(obj)</code> utility function for constructing a <code class="language-plaintext highlighter-rouge">PMMLPipeline</code> object from pre-fitted components, because it is programmed to perform exactly the same extra object initialization work as the <code class="language-plaintext highlighter-rouge">PMMLPipeline.fit(X, y)</code> method is doing.
For example, setting the <code class="language-plaintext highlighter-rouge">PMMLPipeline.active_fields</code> and <code class="language-plaintext highlighter-rouge">PMMLPipeline.target_fields</code> attributes.</p>

<p>The <code class="language-plaintext highlighter-rouge">PMMLPipeline</code> object is enhanced with verification data in order to auto-discover any regressions that might arise from migration from Python platform to other language platforms.
PMML implements <a href="https://dmg.org/pmml/v4-4-1/ModelVerification.html">model verification</a> similarly to the <code class="language-plaintext highlighter-rouge">numpy.isclose</code> utility function.
The main difference is terminological, as relative tolerance and absolute tolerance are called “precision” and “zero threshold”, respectively.</p>

<h2 id="resources">Resources</h2>

<ul>
  <li>Python script: <a href="https://openscoring.io/resources/2023-01-28/train.py"><code class="language-plaintext highlighter-rouge">train.py</code></a></li>
</ul>

</div>



  </main>

  <footer class="footer">
  <div class="container">
    <div class="mb-6">© 2022 - Openscoring</div>

    <div class="mb-6">
      <ul class="flex gap-4 list-none">
        <li>
          <a href="mailto:info@openscoring.io" aria-label="email">
            <img src="/assets/images/email_round.svg" width="48" height="48" alt="Contact Openscoring">
          </a>
        </li>
        <li>
          <a href="https://twitter.com/openscoring" target="_blank" aria-label="twitter">
            <img src="/assets/images/twitter_round.svg" width="48" height="48" alt="Follow Openscoring on Twitter">
          </a>
        </li>
      </ul>
    </div>
  </div>
</footer>

  <script>
  var sc_project=11704106;
  var sc_security="a7d1bf16"; 
  var sc_invisible=1; 
  var sc_remove_link=1; 
</script>

<script src="https://www.statcounter.com/counter/counter.js" async></script>

<noscript>
  <div class="statcounter">
    <img class="statcounter" src="https://c.statcounter.com/11704106/0/a7d1bf16/1/" alt="Web Analytics Made Easy - Statcounter" referrerPolicy="no-referrer-when-downgrade">
  </div>
</noscript>
</body>

</html>
